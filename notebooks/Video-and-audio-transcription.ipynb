{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to Manipulate and Transcribe Audio and Video Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pattyry\n",
    "Nov 14, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim a movie file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import moviepy\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "import subprocess\n",
    "import scipy.io.wavfile as wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = \"c:\\\\\"\n",
    "os.chdir(cwd)\n",
    "filein = \"recording-in.mp4\"\n",
    "fileout = \"recording-out.mp4\"\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set start time and end time, and extract desired clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n"
     ]
    }
   ],
   "source": [
    "start_time =30\n",
    "end_time = 1000000\n",
    "\n",
    "ffmpeg_extract_subclip(filein, start_time, end_time, targetname=fileout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract wav file from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"ffmpeg -i c:/iota/source/recording-out.mp4 -ab 160k -ac 2 -ar 22000 -vn recording-out.wav\"\n",
    "\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk wav's to length limit of speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\iota\\\\transcription'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"c:\\\\transcription\")\n",
    "transcription = os.getcwd()\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recording-out.mp4', 'recording-out.wav']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"c:\\\\source\")\n",
    "source = os.getcwd()\n",
    "source\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22000"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io.wavfile import read as read_wav\n",
    "\n",
    "sampling_rate, data=read_wav(\"recording-out.wav\") # enter your filename\n",
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_rate = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _slice_audio_data(raw_audio_data, interval_len):\n",
    "    accounted_fs = int(sampling_rate * interval_len)   \n",
    "    num_slices = int(len(raw_audio_data) / accounted_fs)   \n",
    "    audio_data = raw_audio_data[: int((num_slices) * accounted_fs)]  # Trims audio array    \n",
    "    remnant = np.array(raw_audio_data[int((num_slices) * accounted_fs): ] )    \n",
    "    sliced_audio = np.array(np.split(audio_data, (num_slices)))    \n",
    "    row_length = np.array(np.zeros(sliced_audio[1].shape))     \n",
    "    row_length[:remnant.shape[0],] = remnant  \n",
    "    sliced_audio = np.vstack([sliced_audio, row_length])\n",
    "    return np.array(sliced_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdir, dirs, files in os.walk(source):\n",
    "    for file in files:\n",
    "        os.chdir(source)\n",
    "        filepath = subdir + os.sep + file\n",
    "        if filepath.endswith(\".wav\"):\n",
    "            fs, data = wavfile.read(filepath)\n",
    "            data = data.sum(axis=1) / 2 #convert from stereo to mono\n",
    "            sliced_audio = _slice_audio_data(data, 600)\n",
    "            sliced_audio = np.asarray(sliced_audio, dtype=np.int16)\n",
    "            os.chdir(transcription)\n",
    "            for i in range(sliced_audio.shape[0]):\n",
    "                num = str(i)\n",
    "                data = sliced_audio[i,:]\n",
    "                # Resample data\n",
    "                number_of_samples = round(len(data) * float(resample_rate) / sampling_rate)\n",
    "                data = sps.resample(sliced_audio[i,:], number_of_samples)\n",
    "                data = np.asarray(data, dtype=np.int16)\n",
    "                # Write data\n",
    "                wavfile.write(num+\"-\"+file, resample_rate, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech to Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import wave\n",
    "import string\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate, data=read_wav(\"0-recording-out.wav\") # enter your filename\n",
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-recording-out.wav',\n",
       " '1-recording-out.wav',\n",
       " '2-recording-out.wav',\n",
       " '3-recording-out.wav',\n",
       " '4-recording-out.wav',\n",
       " '5-recording-out.wav',\n",
       " '6-recording-out.wav',\n",
       " '7-recording-out.wav',\n",
       " '8-recording-out.wav']"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_key, service_region = \"<my-speech-to-text-key\", \"<my-service-location\"\n",
    "speech_config=speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "recordings = os.listdir()\n",
    "recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke Azure Cognitive Services Speech to Text Service Against a List of 10-minute Recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _speech_recognize_continuous_from_file(file, speech_key, service_region, count):\n",
    "    \n",
    "    all_results = []\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    speech_config.speech_recognition_language=\"en-US\"\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=file)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    \n",
    "    done = False\n",
    "\n",
    "    def stop_cb(evt):\n",
    "        \"\"\"callback that stops continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        print('CLOSING on {}'.format(evt))\n",
    "        speech_recognizer.stop_continuous_recognition()\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    all_results = []\n",
    "    def handle_final_result(evt):\n",
    "        all_results.append(evt.result.text)\n",
    "\n",
    "    speech_recognizer.recognized.connect(handle_final_result)\n",
    "    \n",
    "    # Connect callbacks to the events fired by the speech recognizer\n",
    "    speech_recognizer.recognizing.connect(lambda evt: print('RECOGNIZING: {}'.format(evt)))\n",
    "    speech_recognizer.recognized.connect(lambda evt: print('RECOGNIZED: {}'.format(evt)))\n",
    "    speech_recognizer.session_started.connect(lambda evt: print('SESSION STARTED: {}'.format(evt)))\n",
    "    speech_recognizer.session_stopped.connect(lambda evt: print('SESSION STOPPED {}'.format(evt)))\n",
    "    speech_recognizer.canceled.connect(lambda evt: print('CANCELED {}'.format(evt)))\n",
    "\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "\n",
    "    # Start continuous speech recognition\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "    while not done:\n",
    "        time.sleep(1)\n",
    "\n",
    "    with open(count+\"all_results.txt\", \"w\") as output:\n",
    "        output.write(str(all_results))\n",
    "        \n",
    "    return all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_results = []\n",
    "results = []\n",
    "count = 0\n",
    "for i in recordings:\n",
    "    file = \"c://iota//transcription//\"+ i\n",
    "    print(file)\n",
    "    new_results = _speech_recognize_continuous_from_file(file, speech_key, service_region, count)\n",
    "    count = count +1\n",
    "    results.append(new_results)\n",
    "    print(len(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(count+\"concatanated_results.txt\", \"w\") as output:\n",
    "    output.write(str(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
